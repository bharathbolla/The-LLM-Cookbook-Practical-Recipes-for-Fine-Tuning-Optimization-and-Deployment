{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharathbolla/The-LLM-Cookbook-Practical-Recipes-for-Fine-Tuning-Optimization-and-Deployment/blob/main/Chapter_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe-1. Multi-Class Classification (DistilBERT)"
      ],
      "metadata": {
        "id": "a-ol_dtXJI1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate seqeval"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:16:04.757199Z",
          "iopub.execute_input": "2025-06-01T08:16:04.757465Z",
          "iopub.status.idle": "2025-06-01T08:16:12.628252Z",
          "shell.execute_reply.started": "2025-06-01T08:16:04.757420Z",
          "shell.execute_reply": "2025-06-01T08:16:12.627519Z"
        },
        "id": "1Q3Uw1dNrf7i",
        "outputId": "7b500f5d-3d18-4149-c5bb-4f5ecd497586"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=37767c689f66f4451841e024dd4e2a97a005c896f0cbbfe1500d5d9f0e9dd29b\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: fsspec, seqeval, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 seqeval-1.2.2\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets evaluate accelerate torch seqeval"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T07:41:31.624257Z",
          "iopub.execute_input": "2025-05-31T07:41:31.625041Z",
          "iopub.status.idle": "2025-05-31T07:42:58.551839Z",
          "shell.execute_reply.started": "2025-05-31T07:41:31.624996Z",
          "shell.execute_reply": "2025-05-31T07:42:58.550883Z"
        },
        "id": "hpIZBNbxrf7j",
        "outputId": "66747913-efac-4a4d-ab00-9da1f7147d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub import login\n",
        "\n",
        "api = HfApi()\n",
        "whoami = api.whoami(token=\"hf_xxxxxxxxxxxxxxxx\")\n",
        "print(whoami)\n",
        "login(\"hf_xxxxxxxxxxxxxxxxxxxxxx\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T17:19:10.524291Z",
          "iopub.execute_input": "2025-05-31T17:19:10.524909Z",
          "iopub.status.idle": "2025-05-31T17:19:11.255515Z",
          "shell.execute_reply.started": "2025-05-31T17:19:10.524881Z",
          "shell.execute_reply": "2025-05-31T17:19:11.254914Z"
        },
        "id": "dK0_BCLGrf7k",
        "outputId": "bcd48b30-5879-4560-be08-42de6ac8fb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'type': 'user', 'id': '65feba1b57cc48d9d30d11cf', 'name': 'kalpasubbaiah', 'fullname': 'Kalpa Subbaiah', 'email': 'kalpa.subbaiah@gmail.com', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/319094e0eb55ce89334d7bd3685ceeb0.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'hugging_face_token_read', 'role': 'read', 'createdAt': '2025-04-22T09:03:46.223Z'}}}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"TrainingArguments source:\", transformers.TrainingArguments.__module__)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T12:44:48.387824Z",
          "iopub.execute_input": "2025-05-30T12:44:48.388088Z",
          "iopub.status.idle": "2025-05-30T12:44:52.246068Z",
          "shell.execute_reply.started": "2025-05-30T12:44:48.388068Z",
          "shell.execute_reply": "2025-05-30T12:44:52.245241Z"
        },
        "id": "W9YHCxpOrf7k",
        "outputId": "bcd14d59-2dbd-46fd-e41f-1cd8edef506e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Transformers version: 4.51.1\nTrainingArguments source: transformers.training_args\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recipe: Multi-Class Classification (AG News / DistilBERT) ---\n",
        "# Goal: Full fine-tuning of DistilBERT for multi-class text classification.\n",
        "# Dataset: AG News (4 classes: World, Sports, Business, Sci/Tech)\n",
        "# Libraries: transformers, datasets, evaluate, torch\n",
        "# Note: Ensure libraries are installed: pip install transformers datasets evaluate accelerate torch\n",
        "\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        "\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T16:37:30.492402Z",
          "iopub.execute_input": "2025-05-31T16:37:30.492667Z",
          "iopub.status.idle": "2025-05-31T16:37:58.009166Z",
          "shell.execute_reply.started": "2025-05-31T16:37:30.492647Z",
          "shell.execute_reply": "2025-05-31T16:37:58.008524Z"
        },
        "id": "vIdfQl9Arf7l",
        "outputId": "459dd87d-f52e-43ce-f853-85296bd0413f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-05-31 16:37:40.788298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748709461.030554      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748709461.101277      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Configuration ---\n",
        "MODEL_CHECKPOINT = \"distilbert-base-uncased\" # Baseline model\n",
        "DATASET_NAME = \"ag_news\" # Multi-class news topic classification\n",
        "NUM_EPOCHS = 1 # Use 1 epoch for quick demo, 2-3 might yield better results\n",
        "BATCH_SIZE = 16 # Adjust based on GPU memory\n",
        "LEARNING_RATE = 2e-5\n",
        "OUTPUT_DIR = \"./fine_tune_distilbert_agnews_output\" # Directory for this model\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "print(f\"Loading dataset: {DATASET_NAME}\")\n",
        "try:\n",
        "    raw_datasets = load_dataset(DATASET_NAME)\n",
        "    # AG News has 'train' and 'test' splits. Create a validation split from train.\n",
        "    train_val_split = raw_datasets[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "    raw_datasets[\"train\"] = train_val_split[\"train\"]\n",
        "    raw_datasets[\"validation\"] = train_val_split[\"test\"]\n",
        "    print(\"Dataset loaded and split:\")\n",
        "    print(raw_datasets)\n",
        "    # Get label mapping\n",
        "    label_feature = raw_datasets[\"train\"].features[\"label\"]\n",
        "    num_labels = label_feature.num_classes\n",
        "    id_to_label = {i: label for i, label in enumerate(label_feature.names)}\n",
        "    print(f\"Number of labels: {num_labels}\")\n",
        "    print(f\"Label mapping: {id_to_label}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Load Tokenizer ---\n",
        "print(f\"\\nLoading tokenizer for checkpoint: {MODEL_CHECKPOINT}\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Preprocess Data ---\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize text (column name is 'text' in ag_news)\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=False)\n",
        "\n",
        "print(\"\\nTokenizing dataset...\")\n",
        "try:\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "    # Rename 'label' to 'labels' for the Trainer\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "    # Remove original text column\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "    print(\"Tokenization complete. Sample:\")\n",
        "    print(tokenized_datasets[\"train\"][0])\n",
        "except Exception as e:\n",
        "    print(f\"Error during tokenization: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 4. Data Collator ---\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# --- 5. Load Model ---\n",
        "print(f\"\\nLoading model for sequence classification: {MODEL_CHECKPOINT}\")\n",
        "try:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT,\n",
        "        num_labels=num_labels\n",
        "        # Optionally pass id_to_label, label_to_id if needed later\n",
        "    )\n",
        "    print(f\"Model loaded. Initial device: {model.device}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 6. Evaluation Metric ---\n",
        "print(\"\\nLoading evaluation metric: accuracy\")\n",
        "try:\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "    # Could also load F1: f1_metric = evaluate.load(\"f1\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading metric: {e}\")\n",
        "    exit()\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    # Example for adding F1 (requires label count for average)\n",
        "    # f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro') # or 'weighted'\n",
        "    # return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n",
        "    return acc # Just return accuracy for simplicity here\n",
        "\n",
        "# --- 7. Training Arguments ---\n",
        "print(\"\\nDefining Training Arguments...\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "print(f\"Training on device: {training_args.device}\")\n",
        "\n",
        "# --- 8. Initialize Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- 9. Train ---\n",
        "print(\"\\nStarting training...\")\n",
        "try:\n",
        "    train_result = trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "    metrics = train_result.metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()\n",
        "    trainer.save_model(OUTPUT_DIR) # Save final best model\n",
        "    print(f\"Model and training state saved to {OUTPUT_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 10. Evaluate on Test Set ---\n",
        "print(\"\\nEvaluating on the test set...\")\n",
        "try:\n",
        "    test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "    trainer.log_metrics(\"test\", test_results)\n",
        "    trainer.save_metrics(\"test\", test_results)\n",
        "    print(\"Test Set Evaluation Results:\")\n",
        "    print(test_results)\n",
        "except Exception as e:\n",
        "    print(f\"Error during test set evaluation: {e}\")\n",
        "\n",
        "# --- End of Recipe ---"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T12:01:50.152771Z",
          "iopub.execute_input": "2025-05-30T12:01:50.153053Z",
          "iopub.status.idle": "2025-05-30T12:12:22.438538Z",
          "shell.execute_reply.started": "2025-05-30T12:01:50.153033Z",
          "shell.execute_reply": "2025-05-30T12:12:22.437766Z"
        },
        "id": "zdU33zD7rf7l",
        "outputId": "c56754fe-592c-4a0c-b3b6-0ec22ccade4f",
        "colab": {
          "referenced_widgets": [
            "fc575fa9e8634da48e5cc4e747986066"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading dataset: ag_news\nDataset loaded and split:\nDatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 108000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 7600\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 12000\n    })\n})\nNumber of labels: 4\nLabel mapping: {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n\nLoading tokenizer for checkpoint: distilbert-base-uncased\n\nTokenizing dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc575fa9e8634da48e5cc4e747986066"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Tokenization complete. Sample:\n{'labels': tensor(0), 'input_ids': tensor([  101, 13905,  1998,  4963,  1999,  2235,  2845,  2237,  2044,  6859,\n         2022, 14540,  2319,  1010,  3607,  1006, 26665,  1007,  1011,  1996,\n         4288,  1997,  2062,  2084, 13710,  2336,  1010,  3008,  1998,  5089,\n         2076,  1996,  6703,  2203,  2000,  1037,  5187,  1011,  3178,  2082,\n         6859,  2187,  4510,  1037,  2155, 22154,  1999,  1996,  2235,  2845,\n         2237,  1997,  2022, 14540,  2319,  1012,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1])}\n\nLoading model for sequence classification: distilbert-base-uncased\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Model loaded. Initial device: cpu\n\nLoading evaluation metric: accuracy\n\nDefining Training Arguments...\nTraining on device: cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/3240763051.py:131: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nStarting training...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='6750' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6750/6750 10:14, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.204700</td>\n      <td>0.181924</td>\n      <td>0.942417</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Training finished.\n***** train metrics *****\n  epoch                    =        1.0\n  total_flos               =  2527117GF\n  train_loss               =     0.2297\n  train_runtime            = 0:10:14.89\n  train_samples_per_second =    175.638\n  train_steps_per_second   =     10.977\nModel and training state saved to ./fine_tune_distilbert_agnews_output\n\nEvaluating on the test set...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [475/475 00:12]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "***** test metrics *****\n  epoch                   =        1.0\n  eval_accuracy           =     0.9375\n  eval_loss               =     0.1865\n  eval_runtime            = 0:00:12.45\n  eval_samples_per_second =    610.029\n  eval_steps_per_second   =     38.127\nTest Set Evaluation Results:\n{'eval_loss': 0.1865331530570984, 'eval_accuracy': 0.9375, 'eval_runtime': 12.4584, 'eval_samples_per_second': 610.029, 'eval_steps_per_second': 38.127, 'epoch': 1.0}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe-3. Multi-Class Classification (Gemma-2B)"
      ],
      "metadata": {
        "id": "XTcJdY2nJNez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recipe: Multi-Class Classification (AG News / Gemma-2B) ---\n",
        "# Goal: Full fine-tuning of Gemma-2B (a decoder-only SLM) for multi-class text classification.\n",
        "# Dataset: AG News (4 classes: World, Sports, Business, Sci/Tech)\n",
        "# Libraries: transformers, datasets, evaluate, torch, accelerate\n",
        "# Note: Ensure libraries are installed: pip install transformers datasets evaluate accelerate torch sentencepiece\n",
        "#       Fine-tuning Gemma-2B requires significant GPU memory (>16GB VRAM recommended, may need adjustments).\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_CHECKPOINT = \"google/gemma-2b\" # Using Gemma 2B base model\n",
        "DATASET_NAME = \"ag_news\"\n",
        "NUM_EPOCHS = 1 # Use 1 epoch for quick demo\n",
        "# Gemma-2B is larger, requires smaller batch size or gradient accumulation\n",
        "BATCH_SIZE = 4 # Reduced batch size\n",
        "GRADIENT_ACCUMULATION_STEPS = 4 # Simulate batch size of 4*4=16\n",
        "LEARNING_RATE = 1e-5 # Often need smaller LR for larger models\n",
        "OUTPUT_DIR = \"./fine_tune_gemma_agnews_output\" # Directory for this model\n",
        "\n",
        "# Check GPU availability and VRAM\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    # Simple VRAM check (may not be perfectly accurate)\n",
        "    # t = torch.cuda.get_device_properties(0).total_memory\n",
        "    # r = torch.cuda.memory_reserved(0)\n",
        "    # a = torch.cuda.memory_allocated(0)\n",
        "    # free = t - (r + a) # free Gpu memory\n",
        "    # print(f\"Total VRAM: {t / 1024**3:.2f} GB\")\n",
        "    # print(f\"Approx Free VRAM: {free / 1024**3:.2f} GB\")\n",
        "    # if free / 1024**3 < 14: # Rough estimate for Gemma 2B FT\n",
        "    #     print(\"Warning: Low VRAM detected, fine-tuning Gemma-2B might fail.\")\n",
        "    #     print(\"Consider using QLoRA (Chapter 8) or a smaller model.\")\n",
        "else:\n",
        "    print(\"Warning: No GPU detected. Fine-tuning Gemma-2B on CPU will be extremely slow.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T09:34:54.738820Z",
          "iopub.execute_input": "2025-05-31T09:34:54.739422Z",
          "iopub.status.idle": "2025-05-31T09:35:18.558882Z",
          "shell.execute_reply.started": "2025-05-31T09:34:54.739397Z",
          "shell.execute_reply": "2025-05-31T09:35:18.558238Z"
        },
        "id": "cpGPk1rurf7m",
        "outputId": "be5b619f-6acc-4ae0-fd27-e212fb2ff27e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-05-31 09:35:00.946447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748684101.167890      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748684101.236500      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "GPU detected: Tesla T4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T09:35:18.670186Z",
          "iopub.execute_input": "2025-05-31T09:35:18.670393Z",
          "iopub.status.idle": "2025-05-31T09:35:18.685702Z",
          "shell.execute_reply.started": "2025-05-31T09:35:18.670375Z",
          "shell.execute_reply": "2025-05-31T09:35:18.685063Z"
        },
        "id": "nAeA_FnVrf7n"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Data ---\n",
        "print(f\"Loading dataset: {DATASET_NAME}\")\n",
        "try:\n",
        "    raw_datasets = load_dataset(DATASET_NAME)\n",
        "    train_val_split = raw_datasets[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "    raw_datasets[\"train\"] = train_val_split[\"train\"]\n",
        "    raw_datasets[\"validation\"] = train_val_split[\"test\"]\n",
        "    #print(\"Dataset loaded and split:\")\n",
        "    #print(raw_datasets[:2])\n",
        "    label_feature = raw_datasets[\"train\"].features[\"label\"]\n",
        "    num_labels = label_feature.num_classes\n",
        "    id_to_label = {i: label for i, label in enumerate(label_feature.names)}\n",
        "    print(f\"Number of labels: {num_labels}\")\n",
        "    print(f\"Label mapping: {id_to_label}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Load Tokenizer ---\n",
        "print(f\"\\nLoading tokenizer for checkpoint: {MODEL_CHECKPOINT}\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    # Gemma tokenizer might use <pad> ID 0, but explicitly setting can avoid issues\n",
        "    if tokenizer.pad_token is None:\n",
        "        print(\"Setting pad_token to eos_token\")\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        # Important: Resize model embeddings if adding new special tokens AFTER model load\n",
        "        # model.resize_token_embeddings(len(tokenizer))\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Preprocess Data ---\n",
        "def tokenize_function(examples):\n",
        "    # Max length depends on model, Gemma typically supports 2048 or more, but keep shorter for classification\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=False, max_length=512)\n",
        "\n",
        "print(\"\\nTokenizing dataset...\")\n",
        "try:\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "    print(\"Tokenization complete.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during tokenization: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 4. Data Collator ---\n",
        "# Use standard padding collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# --- 5. Load Model ---\n",
        "print(f\"\\nLoading model for sequence classification: {MODEL_CHECKPOINT}\")\n",
        "print(\"This may take a while and require significant RAM/VRAM...\")\n",
        "try:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT,\n",
        "        num_labels=num_labels,\n",
        "        # Add pad_token_id if you explicitly set tokenizer.pad_token = tokenizer.eos_token\n",
        "        # pad_token_id=tokenizer.pad_token_id,\n",
        "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float32 # Use bfloat16 if possible\n",
        "    )\n",
        "    # If PAD token was added/changed AFTER loading tokenizer but BEFORE model, resize needed:\n",
        "    # model.resize_token_embeddings(len(tokenizer))\n",
        "    # Explicitly set pad_token_id in model config if it wasn't set correctly\n",
        "    if model.config.pad_token_id is None:\n",
        "         model.config.pad_token_id = tokenizer.pad_token_id\n",
        "         print(f\"Set model.config.pad_token_id to: {model.config.pad_token_id}\")\n",
        "\n",
        "    print(f\"Model loaded. Initial device: {model.device}\") # Trainer will move it\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Check VRAM, RAM, and potential Hugging Face Hub connectivity issues.\")\n",
        "    exit()\n",
        "\n",
        "# --- 6. Evaluation Metric ---\n",
        "print(\"\\nLoading evaluation metric: accuracy\")\n",
        "try:\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading metric: {e}\")\n",
        "    exit()\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# --- 7. Training Arguments ---\n",
        "print(\"\\nDefining Training Arguments...\")\n",
        "# Check for bfloat16 support for mixed precision\n",
        "bf16_supported = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE * 2, # Can often use larger eval batch size\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50, # Log more frequently with accumulation\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=torch.cuda.is_available() and not bf16_supported, # Use fp16 if bf16 not supported\n",
        "    bf16=bf16_supported, # Use bf16 if supported (preferred for newer GPUs)\n",
        "    gradient_checkpointing=True, # Saves memory at cost of slower training\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "print(f\"Training on device: {training_args.device}\")\n",
        "print(f\"Using Gradient Accumulation: {GRADIENT_ACCUMULATION_STEPS} steps\")\n",
        "print(f\"Effective Batch Size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"Mixed precision (fp16): {training_args.fp16}\")\n",
        "print(f\"Mixed precision (bf16): {training_args.bf16}\")\n",
        "\n",
        "# --- 8. Initialize Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- 9. Train ---\n",
        "print(\"\\nStarting training (Gemma-2B)...\")\n",
        "try:\n",
        "    train_result = trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "    metrics = train_result.metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()\n",
        "    trainer.save_model(OUTPUT_DIR) # Save final best model\n",
        "    print(f\"Model and training state saved to {OUTPUT_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    print(\"This might be an Out-of-Memory (OOM) error. Try reducing batch size, enabling gradient checkpointing, or using LoRA/QLoRA (Chapter 8).\")\n",
        "    exit()\n",
        "\n",
        "# --- 10. Evaluate on Test Set ---\n",
        "print(\"\\nEvaluating on the test set...\")\n",
        "try:\n",
        "    test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "    trainer.log_metrics(\"test\", test_results)\n",
        "    trainer.save_metrics(\"test\", test_results)\n",
        "    print(\"Test Set Evaluation Results:\")\n",
        "    print(test_results)\n",
        "except Exception as e:\n",
        "    print(f\"Error during test set evaluation: {e}\")\n",
        "\n",
        "# --- End of Recipe ---\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T09:35:20.072867Z",
          "iopub.execute_input": "2025-05-31T09:35:20.073148Z",
          "iopub.status.idle": "2025-05-31T09:50:07.157684Z",
          "shell.execute_reply.started": "2025-05-31T09:35:20.073126Z",
          "shell.execute_reply": "2025-05-31T09:50:07.156805Z"
        },
        "id": "3QViACQYrf7n",
        "outputId": "0995b980-2a51-4dd8-fac0-5d2463e44767",
        "colab": {
          "referenced_widgets": [
            "6443219236fc42cfa719e03d1d5b7c4d",
            "0f2d108084094dc4ba6507f49ef8963b",
            "d79fa857e5aa4c3e9a2bb97079336ee8",
            "80f08f02b63c4ef9ab67ab24cca04fd7",
            "c9313371ae5e4c3a8b5c214f45cadb38",
            "e7a3667a76084b3f86a1da259b93a59c",
            "28e67623ca0e4627b3b3cb72aa16e963",
            "65be2fe759874c6ca9c38d2a2eec836e",
            "2a8a5816abab4761bffd7276a3dee096",
            "57071e06eb1940cd816c9d460d29e1f5",
            "8bdcb5e6635345f5bba37ecc501405bc",
            "b744070917a2430b872e43eb7f002bee",
            "6ce12eba5cfa4521a5cffc50aa5f3188",
            "c8863f8e1d514f18a574c77ae9866e31",
            "9e6bc8d74ba042a1be5e9b4653a40165",
            "a34593c704024a3faf742173d22476a8",
            "bf8c1305c743465f982af1008bbbaa98",
            "e546dc28eb724caa90ed137d797c7399",
            "c5ab60d6858d4f60bea6880c0cc444f0"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading dataset: ag_news\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6443219236fc42cfa719e03d1d5b7c4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f2d108084094dc4ba6507f49ef8963b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79fa857e5aa4c3e9a2bb97079336ee8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80f08f02b63c4ef9ab67ab24cca04fd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9313371ae5e4c3a8b5c214f45cadb38"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Number of labels: 4\nLabel mapping: {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n\nLoading tokenizer for checkpoint: google/gemma-2b\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7a3667a76084b3f86a1da259b93a59c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28e67623ca0e4627b3b3cb72aa16e963"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65be2fe759874c6ca9c38d2a2eec836e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a8a5816abab4761bffd7276a3dee096"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nTokenizing dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/108000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57071e06eb1940cd816c9d460d29e1f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bdcb5e6635345f5bba37ecc501405bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b744070917a2430b872e43eb7f002bee"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Tokenization complete.\n\nLoading model for sequence classification: google/gemma-2b\nThis may take a while and require significant RAM/VRAM...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ce12eba5cfa4521a5cffc50aa5f3188"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8863f8e1d514f18a574c77ae9866e31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e6bc8d74ba042a1be5e9b4653a40165"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a34593c704024a3faf742173d22476a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf8c1305c743465f982af1008bbbaa98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e546dc28eb724caa90ed137d797c7399"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of GemmaForSequenceClassification were not initialized from the model checkpoint at google/gemma-2b and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Model loaded. Initial device: cpu\n\nLoading evaluation metric: accuracy\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5ab60d6858d4f60bea6880c0cc444f0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nDefining Training Arguments...\nTraining on device: cuda:0\nUsing Gradient Accumulation: 4 steps\nEffective Batch Size: 16\nMixed precision (fp16): False\nMixed precision (bf16): True\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/1389132619.py:122: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nStarting training (Gemma-2B)...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Error during training: CUDA out of memory. Tried to allocate 1000.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 338.12 MiB is free. Process 5098 has 14.41 GiB memory in use. Of the allocated memory 14.05 GiB is allocated by PyTorch, and 177.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nThis might be an Out-of-Memory (OOM) error. Try reducing batch size, enabling gradient checkpointing, or using LoRA/QLoRA (Chapter 8).\n\nEvaluating on the test set...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='None' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      None\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>2.309317</td>\n      <td>0.270395</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "***** test metrics *****\n  eval_accuracy = 0.2704\n  eval_loss     = 2.3093\nTest Set Evaluation Results:\n{'eval_loss': 2.3093173503875732, 'eval_accuracy': 0.27039473684210524}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe-4: Generative Adaptation (Causal LM Fine-Tuning)"
      ],
      "metadata": {
        "id": "TVwfdWmENFx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recipe: Causal LM Fine-Tuning on Wikitext-2 ---\n",
        "# Goal: Fine-tune GPT-2 on Wikitext-2 with tokenization and block grouping\n",
        "\n",
        "import torch\n",
        "import math\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    pipeline,\n",
        ")\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_CHECKPOINT = \"distilgpt2\"\n",
        "DATASET_NAME = \"wikitext\"\n",
        "DATASET_CONFIG = \"wikitext-2-raw-v1\"\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "BLOCK_SIZE = 128\n",
        "OUTPUT_DIR = \"./fine_tuned_gpt2_wikitext\"\n",
        "\n",
        "# --- 1. Load Dataset Subsets ---\n",
        "print(\"Loading Wikitext dataset...\")\n",
        "train_dataset = load_dataset(DATASET_NAME, DATASET_CONFIG, split=\"train[:5000]\")\n",
        "val_dataset = load_dataset(DATASET_NAME, DATASET_CONFIG, split=\"validation[:500]\")\n",
        "\n",
        "# --- 2. Load Tokenizer ---\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(f\"Set PAD token to EOS token: {tokenizer.pad_token}\")\n",
        "\n",
        "# --- 3. Tokenization ---\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"])\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# --- 4. Group Tokens into Blocks ---\n",
        "def group_texts(examples):\n",
        "    # Concatenate all examples for each key\n",
        "    concatenated = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated[\"input_ids\"])\n",
        "\n",
        "    # Truncate to a multiple of block_size\n",
        "    if total_length >= BLOCK_SIZE:\n",
        "        total_length = (total_length // BLOCK_SIZE) * BLOCK_SIZE\n",
        "\n",
        "    # Split into blocks\n",
        "    result = {\n",
        "        k: [concatenated[k][i : i + BLOCK_SIZE] for i in range(0, total_length, BLOCK_SIZE)]\n",
        "        for k in concatenated.keys()\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "lm_train_dataset = tokenized_train.map(group_texts, batched=True)\n",
        "lm_val_dataset = tokenized_val.map(group_texts, batched=True)\n",
        "\n",
        "# --- 5. Load Model ---\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# --- 6. Data Collator ---\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# --- 7. Training Arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    push_to_hub=False,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# --- 8. Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=lm_train_dataset,\n",
        "    eval_dataset=lm_val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# --- 9. Train ---\n",
        "print(\"\\nTraining...\")\n",
        "trainer.train()\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "\n",
        "# --- 10. Evaluate (Perplexity) ---\n",
        "print(\"\\nEvaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "perplexity = math.exp(eval_results[\"eval_loss\"])\n",
        "print(f\"Perplexity: {perplexity:.2f}\")\n",
        "\n",
        "# --- 11. Generate Text (Optional) ---\n",
        "print(\"\\nGenerating text...\")\n",
        "generator = pipeline(\"text-generation\", model=OUTPUT_DIR, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "prompt = \"Artificial intelligence is\"\n",
        "output = generator(prompt, max_new_tokens=50, num_return_sequences=1)[0][\"generated_text\"]\n",
        "print(f\"Prompt: {prompt}\\nGenerated: {output}\")\n"
      ],
      "metadata": {
        "id": "7H0Ch2WJNF9D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T09:02:05.471410Z",
          "iopub.execute_input": "2025-05-31T09:02:05.471730Z",
          "iopub.status.idle": "2025-05-31T09:02:53.761375Z",
          "shell.execute_reply.started": "2025-05-31T09:02:05.471707Z",
          "shell.execute_reply": "2025-05-31T09:02:53.760755Z"
        },
        "outputId": "0d0edfb3-168c-4c61-dcc3-90290e94657c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading Wikitext dataset...\nSet PAD token to EOS token: <|endoftext|>\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/3786389367.py:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nTraining...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [308/308 00:38, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.967800</td>\n      <td>3.797837</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThere were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEvaluating model...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:01]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Perplexity: 44.60\n\nGenerating text...\nPrompt: Artificial intelligence is\nGenerated: Artificial intelligence is an area of scientific research that often has its limitations due to the complexity and complexity of the data. The underlying cause and source of these anomalies is the \"stalker effect\". In a 2003 article entitled A New Approach to Complex Intelligence, Stephen Hawking and\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe 2.Token Classification Specialization (NER)\n",
        "\n"
      ],
      "metadata": {
        "id": "RCY_RfLtNWiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recipe: Token Classification Specialization (NER) ---\n",
        "# Goal: Full fine-tuning of a pre-trained model for Token Classification (Named Entity Recognition).\n",
        "# Libraries: transformers, datasets, evaluate, seqeval, torch\n",
        "# Note: Ensure libraries are installed: pip install transformers datasets evaluate seqeval accelerate torch\n",
        "#       Uses DistilBERT and CoNLL-2003 dataset. Requires careful label alignment.\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datasets import load_dataset, ClassLabel\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification # Specific data collator for token tasks\n",
        ")\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
        "DATASET_NAME = \"conll2003\" # Common NER dataset\n",
        "NUM_EPOCHS = 1 # Use 1 epoch for quick demo\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "OUTPUT_DIR = \"./fine_tune_ner_output\"\n",
        "# Use a task name prefix for potential model hub uploads (optional)\n",
        "TASK_NAME = \"ner\"\n",
        "LABEL_ALL_TOKENS = True # Whether to align labels for all sub-tokens or just the first\n",
        "\n",
        "# --- 1. Load Data & Labels ---\n",
        "print(f\"Loading dataset: {DATASET_NAME}\")\n",
        "try:\n",
        "    raw_datasets = load_dataset(DATASET_NAME)\n",
        "    print(\"Dataset loaded:\")\n",
        "    print(raw_datasets)\n",
        "\n",
        "    # Extract label list and mappings from dataset features\n",
        "    ner_features = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
        "    label_list = ner_features.feature.names\n",
        "    label_to_id = {label: i for i, label in enumerate(label_list)}\n",
        "    id_to_label = {i: label for i, label in enumerate(label_list)}\n",
        "    num_labels = len(label_list)\n",
        "\n",
        "    print(f\"\\nLabels: {label_list}\")\n",
        "    print(f\"Number of labels: {num_labels}\")\n",
        "    print(f\"\\nExample tokens: {raw_datasets['train'][0]['tokens']}\")\n",
        "    print(f\"Example NER tags (IDs): {raw_datasets['train'][0]['ner_tags']}\")\n",
        "    print(f\"Example NER tags (Labels): {[id_to_label[tag_id] for tag_id in raw_datasets['train'][0]['ner_tags']]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset or extracting labels: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Load Tokenizer ---\n",
        "print(f\"\\nLoading tokenizer for checkpoint: {MODEL_CHECKPOINT}\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    # Check if the tokenizer is fast (required for offset mapping used in label alignment)\n",
        "    if not tokenizer.is_fast:\n",
        "        raise TypeError(\n",
        "            \"This recipe requires a fast tokenizer for offset mapping. \"\n",
        "            f\"Try using {MODEL_CHECKPOINT} without '-base-uncased' or choose another fast tokenizer.\"\n",
        "        )\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Preprocess Data (Tokenize and Align Labels) ---\n",
        "# Function to tokenize inputs and align labels with sub-tokens\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True, # Important: Input is already split into words\n",
        "        padding=False # Padding handled by collator\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"{TASK_NAME}_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i) # Map tokens to original words\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For subsequent tokens in a multi-token word, set label based on LABEL_ALL_TOKENS flag\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if LABEL_ALL_TOKENS else -100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "print(\"\\nTokenizing dataset and aligning labels...\")\n",
        "try:\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_and_align_labels, batched=True)\n",
        "    # Remove original columns no longer needed\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(raw_datasets[\"train\"].column_names)\n",
        "    print(\"Tokenization and alignment complete. Sample:\")\n",
        "    sample = tokenized_datasets[\"train\"][0]\n",
        "    print(f\"Input IDs: {sample['input_ids']}\")\n",
        "    print(f\"Labels: {sample['labels']}\")\n",
        "    # Decode to see alignment (special tokens have label -100)\n",
        "    for token_id, label_id in zip(sample['input_ids'], sample['labels']):\n",
        "         if label_id != -100:\n",
        "              print(f\"{tokenizer.decode([token_id])}: {id_to_label.get(label_id, 'N/A')}\")\n",
        "         else:\n",
        "              print(f\"{tokenizer.decode([token_id])}: IGNORED\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during tokenization/alignment: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 4. Data Collator ---\n",
        "# Handles dynamic padding for token classification tasks\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "# --- 5. Load Model ---\n",
        "print(f\"\\nLoading model for Token Classification: {MODEL_CHECKPOINT}\")\n",
        "try:\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT,\n",
        "        num_labels=num_labels,\n",
        "        id2label=id_to_label, # Pass mappings for better inference/display\n",
        "        label2id=label_to_id\n",
        "    )\n",
        "    print(f\"Model loaded. Initial device: {model.device}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 6. Evaluation Metric (Seqeval) ---\n",
        "print(\"\\nLoading evaluation metric: seqeval (for NER)\")\n",
        "try:\n",
        "    seqeval_metric = evaluate.load(\"seqeval\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading metric: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Function to compute metrics using seqeval\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2) # Get most likely label ID for each token\n",
        "\n",
        "    # Remove ignored index (-100) and convert IDs to label strings\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval_metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    # Return main metrics, can add breakdown per class if needed\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "# --- 7. Training Arguments ---\n",
        "print(\"\\nDefining Training Arguments...\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\", # Use F1 score for NER typically\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "print(f\"Training on device: {training_args.device}\")\n",
        "\n",
        "# --- 8. Initialize Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- 9. Train ---\n",
        "print(\"\\nStarting training...\")\n",
        "try:\n",
        "    train_result = trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "    metrics = train_result.metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    print(f\"Model and training state saved to {OUTPUT_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 10. Evaluate on Test Set ---\n",
        "print(\"\\nEvaluating on the test set...\")\n",
        "try:\n",
        "    test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "    trainer.log_metrics(\"test\", test_results)\n",
        "    trainer.save_metrics(\"test\", test_results)\n",
        "    print(\"Test Set Evaluation Results:\")\n",
        "    print(test_results)\n",
        "except Exception as e:\n",
        "    print(f\"Error during test set evaluation: {e}\")\n",
        "\n",
        "# --- End of Recipe ---\n"
      ],
      "metadata": {
        "id": "dj0cL4IGNW-0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T09:14:05.543965Z",
          "iopub.execute_input": "2025-05-31T09:14:05.544606Z",
          "iopub.status.idle": "2025-05-31T09:16:10.852297Z",
          "shell.execute_reply.started": "2025-05-31T09:14:05.544565Z",
          "shell.execute_reply": "2025-05-31T09:16:10.851374Z"
        },
        "outputId": "5044c6e3-d4a0-4a42-8ea8-2df6ca45f182",
        "colab": {
          "referenced_widgets": [
            "041079d403234c988930bef088b3a383",
            "4eaed03a88b04cf8808896d90ccf7e8e",
            "8fa9efb711894f11ad1662b9a9dd309e",
            "424375e032674aad84069da8b182c785",
            "ab88245edd154db6afa3c20613ce897b",
            "107d3d76b6e1412dbafbdbec3fdb9789",
            "443d928833ef4df4bf70842c6b25adaf",
            "60ad77292eb84fb9bbd6e916dc1b1ce9",
            "d69d524dceed4df0884a5bf465e1cd6b",
            "4b5c6c3c6f204d43a2bd15fad258cd35",
            "50acf2ba5b7c4d5cb7c965579a901049",
            "1a4fcff225fe4159adea0cd41da104ca",
            "b66bff45ccf4491ca98955815ac71ec0",
            "a4d6559ac835486581eb5223fb7b0247",
            "afb35e09318e48d6b9e5569513b3cf9c"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-05-31 09:14:17.149887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748682857.666576      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748682857.804361      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Loading dataset: conll2003\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "041079d403234c988930bef088b3a383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eaed03a88b04cf8808896d90ccf7e8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fa9efb711894f11ad1662b9a9dd309e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "424375e032674aad84069da8b182c785"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab88245edd154db6afa3c20613ce897b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "107d3d76b6e1412dbafbdbec3fdb9789"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset loaded:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})\n\nLabels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\nNumber of labels: 9\n\nExample tokens: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\nExample NER tags (IDs): [3, 0, 7, 0, 0, 0, 7, 0, 0]\nExample NER tags (Labels): ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n\nLoading tokenizer for checkpoint: distilbert-base-uncased\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "443d928833ef4df4bf70842c6b25adaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60ad77292eb84fb9bbd6e916dc1b1ce9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d69d524dceed4df0884a5bf465e1cd6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5c6c3c6f204d43a2bd15fad258cd35"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nTokenizing dataset and aligning labels...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50acf2ba5b7c4d5cb7c965579a901049"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a4fcff225fe4159adea0cd41da104ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b66bff45ccf4491ca98955815ac71ec0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Tokenization and alignment complete. Sample:\nInput IDs: [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102]\nLabels: [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100]\n[CLS]: IGNORED\neu: B-ORG\nrejects: O\ngerman: B-MISC\ncall: O\nto: O\nboycott: O\nbritish: B-MISC\nlamb: O\n.: O\n[SEP]: IGNORED\n\nLoading model for Token Classification: distilbert-base-uncased\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4d6559ac835486581eb5223fb7b0247"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Model loaded. Initial device: cpu\n\nLoading evaluation metric: seqeval (for NER)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afb35e09318e48d6b9e5569513b3cf9c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nDefining Training Arguments...\nTraining on device: cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/3300617695.py:193: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nStarting training...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='439' max='439' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [439/439 01:03, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.114600</td>\n      <td>0.098826</td>\n      <td>0.864806</td>\n      <td>0.883768</td>\n      <td>0.874184</td>\n      <td>0.973088</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Training finished.\n***** train metrics *****\n  epoch                    =        1.0\n  total_flos               =   175116GF\n  train_loss               =     0.2506\n  train_runtime            = 0:01:06.52\n  train_samples_per_second =    211.054\n  train_steps_per_second   =      6.599\nModel and training state saved to ./fine_tune_ner_output\n\nEvaluating on the test set...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [108/108 00:04]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "***** test metrics *****\n  epoch                   =        1.0\n  eval_accuracy           =     0.9669\n  eval_f1                 =     0.8476\n  eval_loss               =     0.1253\n  eval_precision          =     0.8413\n  eval_recall             =     0.8539\n  eval_runtime            = 0:00:05.62\n  eval_samples_per_second =     613.85\n  eval_steps_per_second   =     19.199\nTest Set Evaluation Results:\n{'eval_loss': 0.12528881430625916, 'eval_precision': 0.8413236669784846, 'eval_recall': 0.8539045810586281, 'eval_f1': 0.847567440216751, 'eval_accuracy': 0.9669221738830192, 'eval_runtime': 5.6252, 'eval_samples_per_second': 613.85, 'eval_steps_per_second': 19.199, 'epoch': 1.0}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe-5: Logging with Weights & Biases"
      ],
      "metadata": {
        "id": "O8lYhPG8Onfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T11:41:55.565252Z",
          "iopub.execute_input": "2025-05-31T11:41:55.565710Z",
          "iopub.status.idle": "2025-05-31T11:41:58.550695Z",
          "shell.execute_reply.started": "2025-05-31T11:41:55.565686Z",
          "shell.execute_reply": "2025-05-31T11:41:58.549673Z"
        },
        "id": "l8ziUdFTrf7o",
        "outputId": "bf0e47c6-fef7-46b8-e97e-5a4dfe84dcb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration (Same as Classification Recipe) ---\n",
        "MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
        "DATASET_NAME = \"imdb\"\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "OUTPUT_DIR = \"./fine_tune_classifier_wandb_output\" # Use a different output dir\n",
        "\n",
        "# --- Steps 1-6 (Load Data, Tokenizer, Preprocess, Collator, Model, Metrics) ---\n",
        "# These steps are identical to the 'ch6_recipe_classification_ft' recipe.\n",
        "# For brevity, assume these steps have been executed and we have:\n",
        "# - tokenized_datasets (containing 'train', 'validation', 'test')\n",
        "# - tokenizer\n",
        "# - model\n",
        "# - data_collator\n",
        "# - compute_metrics function\n",
        "# --- Start copy-paste block from ch6_recipe_classification_ft (if running standalone) ---\n",
        "print(f\"Loading dataset: {DATASET_NAME}\")\n",
        "raw_datasets = load_dataset(DATASET_NAME)\n",
        "train_val_split = raw_datasets[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "raw_datasets[\"train\"] = train_val_split[\"train\"]\n",
        "raw_datasets[\"validation\"] = train_val_split[\"test\"]\n",
        "print(f\"Loading tokenizer for checkpoint: {MODEL_CHECKPOINT}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=False)\n",
        "print(\"Tokenizing dataset...\")\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "print(f\"Loading model for sequence classification: {MODEL_CHECKPOINT}\")\n",
        "num_labels = raw_datasets[\"train\"].features[\"label\"].num_classes\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=num_labels)\n",
        "print(\"Loading evaluation metric: accuracy\")\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "# --- End copy-paste block ---\n",
        "\n",
        "\n",
        "# --- 7. Training Arguments (Modified for W&B) ---\n",
        "print(\"\\nDefining Training Arguments with W&B Reporting...\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50, # Log more frequently to see updates in W&B\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    push_to_hub=False,\n",
        "    # *** Key Change: Enable W&B reporting ***\n",
        "    report_to=\"wandb\",\n",
        "    # Optional: Name your W&B run\n",
        "    run_name=f\"{MODEL_CHECKPOINT}-ft-{DATASET_NAME}-demo\"\n",
        ")\n",
        "print(f\"Training on device: {training_args.device}\")\n",
        "print(f\"Reporting to W&B project: {WANDB_PROJECT_NAME}\")\n",
        "\n",
        "# --- 8. Initialize Trainer (Same as before) ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- 9. Train (W&B logging happens automatically) ---\n",
        "print(\"\\nStarting training (logging to W&B)...\")\n",
        "# You should see W&B links printed in your console output.\n",
        "try:\n",
        "    train_result = trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "    metrics = train_result.metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()\n",
        "    trainer.save_model(OUTPUT_DIR)\n",
        "    print(f\"Model and training state saved to {OUTPUT_DIR}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    # Ensure W&B run is finished even if there's an error\n",
        "    import wandb\n",
        "    wandb.finish()\n",
        "    exit()\n",
        "\n",
        "# --- 10. Evaluate on Test Set (Also logged to W&B) ---\n",
        "print(\"\\nEvaluating on the test set (logging to W&B)...\")\n",
        "try:\n",
        "    test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "    trainer.log_metrics(\"test\", test_results)\n",
        "    trainer.save_metrics(\"test\", test_results)\n",
        "    print(\"Test Set Evaluation Results:\")\n",
        "    print(test_results)\n",
        "except Exception as e:\n",
        "    print(f\"Error during test set evaluation: {e}\")\n",
        "\n",
        "# --- 11. Finish W&B Run ---\n",
        "# Important to properly close the W&B run\n",
        "import wandb\n",
        "wandb.finish()\n",
        "print(\"\\nW&B run finished.\")\n",
        "\n",
        "# --- End of Recipe ---\n"
      ],
      "metadata": {
        "id": "zb_q026UOoqE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T16:59:07.275049Z",
          "iopub.execute_input": "2025-05-31T16:59:07.275468Z",
          "iopub.status.idle": "2025-05-31T17:14:20.298920Z",
          "shell.execute_reply.started": "2025-05-31T16:59:07.275434Z",
          "shell.execute_reply": "2025-05-31T17:14:20.298328Z"
        },
        "outputId": "52446dd8-e8f3-46f3-8387-384697353211",
        "colab": {
          "referenced_widgets": [
            "3870081716d447788c104ef113cbe361"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading dataset: imdb\nLoading tokenizer for checkpoint: distilbert-base-uncased\nTokenizing dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3870081716d447788c104ef113cbe361"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Loading model for sequence classification: distilbert-base-uncased\nLoading evaluation metric: accuracy\n\nDefining Training Arguments with W&B Reporting...\nTraining on device: cuda:0\nReporting to W&B project: llm-cookbook-finetuning-demo\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/1555914802.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nStarting training (logging to W&B)...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='704' max='704' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [704/704 10:53, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.214700</td>\n      <td>0.210556</td>\n      <td>0.919200</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./fine_tune_classifier_wandb_output/checkpoint-704)... Done. 2.0s\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Training finished.\n***** train metrics *****\n  epoch                    =        1.0\n  total_flos               =  2774981GF\n  train_loss               =     0.2577\n  train_runtime            = 0:10:50.28\n  train_samples_per_second =       34.6\n  train_steps_per_second   =      1.083\nModel and training state saved to ./fine_tune_classifier_wandb_output\n\nEvaluating on the test set (logging to W&B)...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [782/782 03:57]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "***** test metrics *****\n  epoch                   =        1.0\n  eval_accuracy           =     0.9231\n  eval_loss               =     0.1974\n  eval_runtime            = 0:03:57.43\n  eval_samples_per_second =    105.291\n  eval_steps_per_second   =      3.294\nTest Set Evaluation Results:\n{'eval_loss': 0.19743402302265167, 'eval_accuracy': 0.92308, 'eval_runtime': 237.4365, 'eval_samples_per_second': 105.291, 'eval_steps_per_second': 3.294, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇████</td></tr><tr><td>train/grad_norm</td><td>▇▆▄█▂▁█▂▃▆▁▄▄▆</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▂▁▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92308</td></tr><tr><td>eval/loss</td><td>0.19743</td></tr><tr><td>eval/runtime</td><td>237.4365</td></tr><tr><td>eval/samples_per_second</td><td>105.291</td></tr><tr><td>eval/steps_per_second</td><td>3.294</td></tr><tr><td>total_flos</td><td>2979614035606656.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>704</td></tr><tr><td>train/grad_norm</td><td>441976.96875</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2147</td></tr><tr><td>train_loss</td><td>0.25768</td></tr><tr><td>train_runtime</td><td>650.2821</td></tr><tr><td>train_samples_per_second</td><td>34.6</td></tr><tr><td>train_steps_per_second</td><td>1.083</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">distilbert-base-uncased-ft-imdb-manual</strong> at: <a href='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo/runs/aewd027v' target=\"_blank\">https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo/runs/aewd027v</a><br> View project at: <a href='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo' target=\"_blank\">https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250531_165451-aewd027v/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nW&B run finished.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recipe: Tracking Your Cook (Logging with W&B) ---\n",
        "# Goal: Integrate Weights & Biases (W&B) for experiment tracking during fine-tuning.\n",
        "# Note: Requires a W&B account (free for personal use).\n",
        "#       Run `pip install wandb`\n",
        "#       Log in via CLI: `wandb login` (or set WANDB_API_KEY environment variable).\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "import os # For setting environment variables (optional)\n",
        "\n",
        "# --- W&B Configuration ---\n",
        "\n",
        "# Set your W&B project name. Runs will be logged here.\n",
        "WANDB_PROJECT_NAME = \"llm-cookbook-finetuning-demo\"\n",
        "os.environ[\"WANDB_PROJECT\"] = WANDB_PROJECT_NAME\n",
        "os.environ[\"WANDB_API_KEY\"] = \"INPUT YOUR API KEY\"\n",
        "# Optional: Set WANDB_LOG_MODEL to 'checkpoint' to automatically log model checkpoints to W&B\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "\n",
        "import wandb\n",
        "wandb.login(key=\"INPUT YOUR API KEY\")\n",
        "wandb.init(project=WANDB_PROJECT_NAME, name=f\"{MODEL_CHECKPOINT}-ft-{DATASET_NAME}-manual\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-31T16:54:43.732207Z",
          "iopub.execute_input": "2025-05-31T16:54:43.732510Z",
          "iopub.status.idle": "2025-05-31T16:54:58.592231Z",
          "shell.execute_reply.started": "2025-05-31T16:54:43.732489Z",
          "shell.execute_reply": "2025-05-31T16:54:58.591567Z"
        },
        "id": "308nCqU-rf7p",
        "outputId": "55e0b36c-447b-4412-c16a-b1bb4cf160f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250531_165451-aewd027v</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo/runs/aewd027v' target=\"_blank\">distilbert-base-uncased-ft-imdb-manual</a></strong> to <a href='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo' target=\"_blank\">https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo/runs/aewd027v' target=\"_blank\">https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo/runs/aewd027v</a>"
          },
          "metadata": {}
        },
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kalpa-subbaiah-mico/llm-cookbook-finetuning-demo/runs/aewd027v?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
            "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f97f8398610>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Recipe: The Taste Test (Comparing Before & After Fine-Tuning)"
      ],
      "metadata": {
        "id": "VXRWjLYkPHpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Full Script: Evaluate Base → Fine-Tune → Evaluate Fine-Tuned Model on IMDB ---\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
        "FINE_TUNED_MODEL_PATH = \"./fine_tune_classifier_output\"\n",
        "DATASET_NAME = \"imdb\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 1\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# --- Load Dataset ---\n",
        "print(\"Loading dataset...\")\n",
        "raw_datasets = load_dataset(DATASET_NAME)\n",
        "num_labels = raw_datasets[\"train\"].features[\"label\"].num_classes\n",
        "test_dataset_raw = raw_datasets[\"test\"]\n",
        "\n",
        "# --- Load Tokenizer ---\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_CHECKPOINT)\n",
        "\n",
        "# --- Load Metric ---\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# --- Tokenize Test Set (for both base and fine-tuned) ---\n",
        "print(\"\\nTokenizing test set...\")\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_test_dataset = test_dataset_raw.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"text\"])\n",
        "tokenized_test_dataset = tokenized_test_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_test_dataset.set_format(\"torch\")\n",
        "\n",
        "# --- 1. Evaluate BASE Model ---\n",
        "print(f\"\\n--- Evaluating BASE Model ({BASE_MODEL_CHECKPOINT}) ---\")\n",
        "try:\n",
        "    base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_CHECKPOINT, num_labels=num_labels)\n",
        "    print(\"Base model loaded.\")\n",
        "\n",
        "    eval_args = TrainingArguments(\n",
        "        output_dir=\"./eval_base_output\",\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        do_train=False,\n",
        "        do_eval=True,\n",
        "        report_to=\"none\",\n",
        "        fp16=torch.cuda.is_available()\n",
        "    )\n",
        "\n",
        "    base_trainer = Trainer(\n",
        "        model=base_model,\n",
        "        args=eval_args,\n",
        "        eval_dataset=tokenized_test_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    base_eval_results = base_trainer.evaluate()\n",
        "    base_accuracy = base_eval_results.get(\"eval_accuracy\", \"N/A\")\n",
        "    print(\"\\nBase Model Evaluation Results:\")\n",
        "    print(base_eval_results)\n",
        "except Exception as e:\n",
        "    print(f\"Error during base model evaluation: {e}\")\n",
        "    base_accuracy = \"Error\"\n",
        "\n",
        "# --- 2. Fine-Tune the Model ---\n",
        "print(\"\\n--- Fine-tuning the model ---\")\n",
        "\n",
        "# Tokenize train/val\n",
        "train_val_split = raw_datasets[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = train_val_split[\"train\"]\n",
        "val_dataset = train_val_split[\"test\"]\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_train = tokenized_train.remove_columns([\"text\"]).rename_column(\"label\", \"labels\").with_format(\"torch\")\n",
        "tokenized_val = tokenized_val.remove_columns([\"text\"]).rename_column(\"label\", \"labels\").with_format(\"torch\")\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_CHECKPOINT, num_labels=num_labels)\n",
        "\n",
        "# Training arguments\n",
        "train_args = TrainingArguments(\n",
        "    output_dir=FINE_TUNED_MODEL_PATH,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(FINE_TUNED_MODEL_PATH)\n",
        "print(f\"Fine-tuned model saved to {FINE_TUNED_MODEL_PATH}\")\n",
        "\n",
        "# --- 3. Evaluate FINE-TUNED Model ---\n",
        "print(f\"\\n--- Evaluating FINE-TUNED Model ({FINE_TUNED_MODEL_PATH}) ---\")\n",
        "try:\n",
        "    fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(FINE_TUNED_MODEL_PATH)\n",
        "\n",
        "    ft_trainer = Trainer(\n",
        "        model=fine_tuned_model,\n",
        "        args=eval_args,  # Reuse the same eval_args\n",
        "        eval_dataset=tokenized_test_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    ft_eval_results = ft_trainer.evaluate()\n",
        "    ft_accuracy = ft_eval_results.get(\"eval_accuracy\", \"N/A\")\n",
        "    print(\"\\nFine-Tuned Model Evaluation Results:\")\n",
        "    print(ft_eval_results)\n",
        "except Exception as e:\n",
        "    print(f\"Error during fine-tuned model evaluation: {e}\")\n",
        "    ft_accuracy = \"Error\"\n",
        "\n",
        "# --- 4. Final Comparison ---\n",
        "print(\"\\n--- Accuracy Comparison ---\")\n",
        "print(f\"Base Model Accuracy:      {base_accuracy:.4f}\" if isinstance(base_accuracy, float) else base_accuracy)\n",
        "print(f\"Fine-Tuned Model Accuracy:{ft_accuracy:.4f}\" if isinstance(ft_accuracy, float) else ft_accuracy)\n"
      ],
      "metadata": {
        "id": "Zedu1SVYO9SN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:21:39.763289Z",
          "iopub.execute_input": "2025-06-01T08:21:39.763606Z",
          "iopub.status.idle": "2025-06-01T08:39:54.661206Z",
          "shell.execute_reply.started": "2025-06-01T08:21:39.763583Z",
          "shell.execute_reply": "2025-06-01T08:39:54.660330Z"
        },
        "outputId": "934102cd-05a2-4103-f350-8518ec10c0e6",
        "colab": {
          "referenced_widgets": [
            "2820aeb1440846799a36eba0cc87d2e0"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading dataset...\nLoading tokenizer...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nTokenizing test set...\n\n--- Evaluating BASE Model (distilbert-base-uncased) ---\nBase model loaded.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/1973684533.py:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  base_trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [782/782 03:42]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nBase Model Evaluation Results:\n{'eval_loss': 0.6908515691757202, 'eval_accuracy': 0.54072, 'eval_runtime': 223.4219, 'eval_samples_per_second': 111.896, 'eval_steps_per_second': 3.5}\n\n--- Fine-tuning the model ---\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/22500 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2820aeb1440846799a36eba0cc87d2e0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_31/1973684533.py:115: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='704' max='704' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [704/704 10:31, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.272000</td>\n      <td>0.215122</td>\n      <td>0.914400</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Fine-tuned model saved to ./fine_tune_classifier_output\n\n--- Evaluating FINE-TUNED Model (./fine_tune_classifier_output) ---\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/1973684533.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  ft_trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [782/782 03:42]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nFine-Tuned Model Evaluation Results:\n{'eval_loss': 0.19901823997497559, 'eval_accuracy': 0.92188, 'eval_runtime': 222.6905, 'eval_samples_per_second': 112.263, 'eval_steps_per_second': 3.512}\n\n--- Accuracy Comparison ---\nBase Model Accuracy:      0.5407\nFine-Tuned Model Accuracy:0.9219\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}